from src.utils import extract_keywords
import streamlit as st
import joblib
import spacy

# ---------------------------
# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
# ---------------------------
vectorizer = joblib.load("notebooks/models/vectorizer.joblib")
kmeans = joblib.load("notebooks/models/kmeans_model.joblib")
nlp = spacy.load("ja_ginza")

# ---------------------------
# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
# ---------------------------
st.title("ğŸ§  ã‚ãªãŸã®èªå½™ã‹ã‚‰ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨ºæ–­ï¼")
text = st.text_area("ã‚ãªãŸã®æœ€è¿‘ã®SNSæŠ•ç¨¿ã‚„æ—¥è¨˜ã£ã½ã„æ–‡ç« ã‚’è²¼ã£ã¦ãã ã•ã„")

# ---------------------------
# è§£æå‡¦ç†
# ---------------------------
if text:
    tokens = extract_keywords(text)  # â† utilsã‹ã‚‰é–¢æ•°ã‚’å‘¼ã³å‡ºã—
    joined = " ".join(tokens)
    vec = vectorizer.transform([joined])
    cluster = kmeans.predict(vec)[0]

    st.subheader("ğŸ§¬ ã‚ãªãŸã®è¨ºæ–­çµæœ")
    st.markdown(f"### âœ… ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå·ï¼š`{cluster}`")
    st.write("â€» ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´ã¥ã‘ã¯ä»Šå¾Œè¿½åŠ äºˆå®šï¼")

    st.subheader("ğŸ” ä½¿ç”¨ã•ã‚ŒãŸèªå½™ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰")
    st.write(tokens)
